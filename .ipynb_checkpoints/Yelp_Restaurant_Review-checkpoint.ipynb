{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Yelp Restaurant Review Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Classification model with numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import nltk\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from collections import Counter\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random as rd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "yelp = pd.read_csv('Yelp Data Restaurant Reviews Ratings.csv')\n",
    "\n",
    "yelp['Ratings'] = 0\n",
    "\n",
    "mask = yelp['stars'] > 3\n",
    "yelp.ix[mask, 'Ratings'] = 1\n",
    "yelp = yelp.drop('stars', 1)\n",
    "\n",
    "Y, X = dmatrices('Ratings ~ 0+ votes_cool+ votes_funny+ votes_useful+ Cheap+ Moderate+ Expensive+ VeryExpensive+ American+ Chinese+ French+ Japanese+ Indian+ Italian + Greek+ Mediterranean+ Mexican+ Thai+ Vietnamese', yelp, return_type = \"dataframe\")\n",
    "y = Y['Ratings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets fit a tree to this data and check how accurately it is able to classify based on the numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Splitting the data into Train and Test data in the ratio of 7:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Run the model, get the predicted values and then compare with the actual data in the test to find the accuracy of our tree classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy -  0.684977498393\n",
      "MODEL: Trees\n",
      "\n",
      "The precision for this classifier is 0.687370956641\n",
      "The recall for this classifier is 0.979406717333\n",
      "The f1 for this classifier is 0.807805075321\n",
      "The accuracy for this classifier is 0.683166666667\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.05      0.10      1921\n",
      "        1.0       0.69      0.98      0.81      4079\n",
      "\n",
      "avg / total       0.64      0.68      0.58      6000\n",
      "\n",
      "\n",
      "Here is the confusion matrix:\n",
      "[[ 104 1817]\n",
      " [  84 3995]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_train)\n",
    "\n",
    "print 'Train Accuracy - ', metrics.accuracy_score(y_train, y_predicted)\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "print \"MODEL: Trees\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_predicted))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_predicted))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_predicted))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_predicted))\n",
    "\n",
    "print '\\nHere is the classification report:'\n",
    "print classification_report(y_test, y_predicted)\n",
    "\n",
    "print '\\nHere is the confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####The Tree Classification model gives us the accuracy of 67.96%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Applying Logistic Regression Model and check if it gives better accuracy than the Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy -  0.684977498393\n",
      "MODEL: Trees\n",
      "\n",
      "The precision for this classifier is 0.687370956641\n",
      "The recall for this classifier is 0.979406717333\n",
      "The f1 for this classifier is 0.807805075321\n",
      "The accuracy for this classifier is 0.683166666667\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.05      0.10      1921\n",
      "        1.0       0.69      0.98      0.81      4079\n",
      "\n",
      "avg / total       0.64      0.68      0.58      6000\n",
      "\n",
      "\n",
      "Here is the confusion matrix:\n",
      "[[ 104 1817]\n",
      " [  84 3995]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_train)\n",
    "\n",
    "print 'Logistic Regression Model Accuracy - ', metrics.accuracy_score(y_train, y_predicted)\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "print \"MODEL: Logistic Regression\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_predicted))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_predicted))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_predicted))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_predicted))\n",
    "\n",
    "print '\\nHere is the classification report:'\n",
    "print classification_report(y_test, y_predicted)\n",
    "\n",
    "print '\\nHere is the confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####We see that Logistic Regression Model gives us better Accuracy of 68.49% than the Tree Model(67.96%) in this classifcation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model with reviews (text) data without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 8104, 0: 3895})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_review = yelp[['Ratings', 'Review']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(yelp_review['Review'], yelp_review['Ratings'], test_size=0.4, random_state=1)\n",
    "\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Before running the Multinomial Naive Bayes Model on the Training Data, we make the proportions of High and Low Rating Reviews in the Training Data Set to be equal to remove the skewness from our Training Data and hence obtain better results on the Test Data Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "y_train_df_0 = y_train_df[y_train_df['Ratings']==1]\n",
    "\n",
    "sampleset = rd.sample(y_train_df_0.index,3895)\n",
    "\n",
    "y_train_0 = y_train.ix[sampleset]\n",
    "\n",
    "X_train_0 = X_train.ix[sampleset]\n",
    "\n",
    "y1index = y_train_df[y_train_df['Ratings']==0].index\n",
    "\n",
    "y_train_1 = y_train.ix[y1index]\n",
    "\n",
    "X_train_1 = X_train.ix[y1index]\n",
    "\n",
    "X_train = pd.concat([X_train_1,X_train_0], axis = 0)\n",
    "y_train = pd.concat([y_train_1,y_train_0], axis = 0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2, \n",
    " ngram_range=(1, 1), \n",
    " strip_accents='unicode',\n",
    " stop_words = 'english', \n",
    " norm='l2')\n",
    "\n",
    "X_train_Orig = X_train\n",
    "X_test_Orig = X_test\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Multinomial Naive Bayes\n",
      "\n",
      "The precision for this classifier is 0.90224325993\n",
      "The recall for this classifier is 0.804551293815\n",
      "The f1 for this classifier is 0.850601474583\n",
      "The accuracy for this classifier is 0.8075\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.81      0.73      2551\n",
      "          1       0.90      0.80      0.85      5449\n",
      "\n",
      "avg / total       0.83      0.81      0.81      8000\n",
      "\n",
      "\n",
      "Here is the confusion matrix:\n",
      "[[2076  475]\n",
      " [1065 4384]]\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_nb_predicted = nb_classifier.predict(X_test)\n",
    "\n",
    "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_nb_predicted))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_nb_predicted))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_nb_predicted))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_nb_predicted))\n",
    "\n",
    "print '\\nHere is the classification report:'\n",
    "print classification_report(y_test, y_nb_predicted)\n",
    "\n",
    "print '\\nHere is the confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####The accuracy obtained using Multinomial naive bayes is 80.75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Classification model with reviews (text) data without stop words and using Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 8104, 0: 3895})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "xn = yelp[['votes_cool', 'votes_funny', 'votes_useful', 'Cheap', 'Moderate', 'Expensive', 'VeryExpensive', 'American', 'Chinese', 'French', 'Japanese', 'Indian', 'Italian', 'Greek', 'Mediterranean', 'Mexican', 'Thai', 'Vietnamese', 'Review']]\n",
    "yn = yelp['Ratings']\n",
    "\n",
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(yelp[['votes_cool', 'votes_funny', 'votes_useful', 'Cheap', 'Moderate', 'Expensive', \n",
    "                                                              'VeryExpensive', 'American', 'Chinese', 'French', 'Japanese', 'Indian', 'Italian', \n",
    "                                                              'Greek', 'Mediterranean', 'Mexican', 'Thai', 'Vietnamese', 'Review']], yelp['Ratings'], \n",
    "                                                        test_size=0.4, random_state=1)\n",
    "\n",
    "Counter(yn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Before running the Multinomial Naive Bayes Model on the Training Data, we make the proportions of High and Low Rating Reviews in the Training Data Set to be equal to remove the skewness from our Training Data and hence obtain better results on the Test Data Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yn_train_df = pd.DataFrame(yn_train)\n",
    "\n",
    "yn_train_df_0 = yn_train_df[yn_train_df['Ratings']==1]\n",
    "\n",
    "yn_train_df = pd.DataFrame(yn_train)\n",
    "\n",
    "yn_train_df_0 = yn_train_df[yn_train_df['Ratings']==1]\n",
    "\n",
    "sampleset = rd.sample(yn_train_df_0.index,3895)\n",
    "\n",
    "yn_train_0 = yn_train.ix[sampleset]\n",
    "\n",
    "Xn_train_0 = Xn_train.ix[sampleset]\n",
    "\n",
    "y1index = yn_train_df[yn_train_df['Ratings']==0].index\n",
    "\n",
    "yn_train_1 = yn_train.ix[y1index]\n",
    "\n",
    "Xn_train_1 = Xn_train.ix[y1index]\n",
    "\n",
    "Xn_train = pd.concat([Xn_train_1,Xn_train_0], axis = 0)\n",
    "yn_train = pd.concat([yn_train_1,yn_train_0], axis = 0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2, \n",
    " ngram_range=(1, 1), \n",
    " strip_accents='unicode', \n",
    " norm='l2')\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train_Orig)\n",
    "X_test = vectorizer.transform(X_test_Orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Xn_train = np.array(Xn_train[['votes_cool', 'votes_funny', 'votes_useful', 'Cheap', 'Moderate', 'Expensive', 'VeryExpensive', 'American',\n",
    "                              'Chinese', 'French', 'Japanese', 'Indian', 'Italian', 'Greek', 'Mediterranean', 'Mexican', 'Thai', 'Vietnamese']])\n",
    "yn_train = np.array(yn_train)\n",
    "\n",
    "Xn_test = np.array(Xn_test[['votes_cool', 'votes_funny', 'votes_useful', 'Cheap', 'Moderate', 'Expensive', 'VeryExpensive', 'American', 'Chinese',\n",
    "                            'French', 'Japanese', 'Indian', 'Italian', 'Greek', 'Mediterranean', 'Mexican', 'Thai', 'Vietnamese']])\n",
    "yn_test = np.array(yn_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Normalized the numeric data to make it perform more accurately during classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xn_train = normalize(Xn_train, axis=1, norm='l1')\n",
    "Xn_test = normalize(Xn_test, axis=1, norm='l1')\n",
    "Xt_train = np.concatenate([X_train.toarray(), Xn_train], axis = 1)\n",
    "Xt_test = np.concatenate([X_test.toarray(), Xn_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Multinomial Naive Bayes\n",
      "\n",
      "The precision for this classifier is 0.906171809842\n",
      "The recall for this classifier is 0.797577537163\n",
      "The f1 for this classifier is 0.84841386042\n",
      "The accuracy for this classifier is 0.805875\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.82      0.73      2551\n",
      "          1       0.91      0.80      0.85      5449\n",
      "\n",
      "avg / total       0.83      0.81      0.81      8000\n",
      "\n",
      "\n",
      "Here is the confusion matrix:\n",
      "[[2101  450]\n",
      " [1103 4346]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB().fit(Xt_train, yn_train)\n",
    "\n",
    "y_nb_predicted = nb_classifier.predict(Xt_test)\n",
    "\n",
    "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_nb_predicted))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_nb_predicted))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_nb_predicted))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_nb_predicted))\n",
    "\n",
    "print '\\nHere is the classification report:'\n",
    "print classification_report(yn_test, y_nb_predicted)\n",
    "\n",
    "print '\\nHere is the confusion matrix:'\n",
    "print metrics.confusion_matrix(yn_test, y_nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy of the model is very similar to the model with just the text data. The text data which was a better predictor of the model earlier still the dominating feature for prediction and hence there is minimal change in the accuracy even after the inclusion of numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Using SentiStrength to analyze the sentiments from the reviews in the dataset and building a Logit model for calculating the ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####After running the Senti-Strength software, we obtain the positive and negative sentiments for each review.To this, we add another column of 'NetSentiment' which is the sum of 'Positive' and 'Negative' Sentiment. We use NetSentiment as the single independent variable in our classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_senti_data = pd.read_csv('net_sentiment.csv')\n",
    "                             \n",
    "# yelp_senti_data[:20]\n",
    "yelp_senti_data[\"Class\"]=1\n",
    "mask = (yelp_senti_data['stars']<=3)\n",
    "yelp_senti_data['Class'][mask] = 0\n",
    "\n",
    "formula = 'Class ~ 0 + NetSentiment'        \n",
    "Y, X = dmatrices(formula, yelp_senti_data, return_type='dataframe')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Applying the Logistic Regression Model using 'NetSentiment' as the predictor variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Logical Regression using SentStrength Data\n",
      "\n",
      "The precision for this classifier is 0.732625482625\n",
      "The recall for this classifier is 0.930375091934\n",
      "The f1 for this classifier is 0.819742952803\n",
      "The accuracy for this classifier is 0.721833333333\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.28      0.39      1921\n",
      "        1.0       0.73      0.93      0.82      4079\n",
      "\n",
      "avg / total       0.71      0.72      0.68      6000\n",
      "\n",
      "\n",
      "Here is the confusion matrix:\n",
      "[[ 536 1385]\n",
      " [ 284 3795]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "\n",
    "prediction_train = model.predict(X_train)\n",
    "\n",
    "y_prediction  = model.predict(X_test)\n",
    "\n",
    "print \"MODEL: Logical Regression using SentStrength Data\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(y_test, y_prediction))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(y_test, y_prediction))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(y_test, y_prediction))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(y_test, y_prediction))\n",
    "\n",
    "print '\\nHere is the classification report:'\n",
    "print classification_report(y_test, y_prediction)\n",
    "\n",
    "print '\\nHere is the confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 “attributes” of a restaurant that are associated with high and low ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Binning the Dataset into Low and High Rating Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp=pd.read_csv('Yelp Data Restaurant Reviews Ratings.csv', encoding='utf-8')\n",
    "yelp.columns.values\n",
    "yelp['rating']=0\n",
    "yelp.ix[yelp['stars']>=4,'rating']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Applying the Multinomial Naive Bayes Model to find out the top 5 attributes associated with High and Low rating reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high rating reviews words [u'gem' u'amazing' u'highly' u'perfect' u'die']\n",
      "gem        1.965407\n",
      "amazing    1.707398\n",
      "highly     1.697840\n",
      "perfect    1.673197\n",
      "die        1.628526\n",
      "dtype: float64\n",
      "low review rating words [u'tasteless' u'worse' u'worst' u'awful' u'terrible']\n",
      "tasteless   -2.737525\n",
      "worse       -2.317327\n",
      "worst       -2.277860\n",
      "awful       -2.209369\n",
      "terrible    -2.194620\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=2, \n",
    " ngram_range=(1, 1), \n",
    " stop_words = 'english', \n",
    " strip_accents='unicode', \n",
    " norm='l2')\n",
    "X = vectorizer.fit_transform(yelp['Review'])\n",
    "\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(X, yelp['rating'])\n",
    "\n",
    "feature_importances = model.feature_log_prob_[1] - model.feature_log_prob_[0]\n",
    "feature_importance_series = Series(feature_importances, index=vectorizer.get_feature_names())  \n",
    "\n",
    "print 'high rating reviews words', feature_importance_series.order(ascending=False)[:5].index.values\n",
    "print feature_importance_series.order(ascending=False)[:5]\n",
    "print 'low review rating words', feature_importance_series.order(ascending=True)[:5].index.values\n",
    "print feature_importance_series.order(ascending=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Attributes associated with high rating reviews are 'gem' , 'amazing' , 'highly' , 'perfect' and  'die' \n",
    "#### Top 5 Attributes associated with low rating reviews are 'tasteless' , 'worse' , 'worst' , 'awful' and  'terrible'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
